---
title: "Introducing GPT-5.2-Codex"
description: "The most advanced agentic coding model for professional software engineering and defensive cybersecurity."
date: "2024-12-31"
tags: ["Product", "Release"]
category: "Product"
ctaButtons:
  - label: "Get started"
    href: "#"
    variant: "primary"
headerCodeSnippet: "npm i -g @openai/codex"
---

Today we're releasing GPT-5.2-Codex, the most advanced agentic coding model yet for complex, real-world software engineering. GPT-5.2-Codex is a version of [GPT-5.2](/blog/gpt-5-2) further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.

As our models continue to advance along the intelligence frontier, we've observed that these improvements also translate to capability jumps in specialized domains such as [cybersecurity](/safety). For example, just last week, a security researcher using GPT-5.2-Codex-Max with Codex CLI found and responsibly disclosed a critical vulnerability in React that could lead to source code exposure.

## Doubling down on code generation

Our research shows that specialized training on code not only improves programming capabilities but also enhances general reasoning and logic. GPT-5.2-Codex demonstrates this transfer learning effect, showing improvements in math and logic tasks compared to generalized models of the same size.

Key improvements include:

- **Context Window:** Expanded to 128k tokens, allowing for analysis of entire repositories.
- **Latency:** Optimized inference for faster code completion suggestions.
- **Accuracy:** A 14% increase in pass@1 rate on HumanEval over GPT-5-Turbo.

```bash
# Install the Codex CLI
npm install -g @openai/codex

# Initialize a new project
codex init my-app --stack next,tailwind,expert-mode

# Generate a complex feature
codex generate "Create a real-time dashboard with WebSockets"
```

## Advancing the open frontier

We believe that powerful coding models can significantly accelerate software development and lower the barrier to entry for building technology. By automating routine tasks and providing intelligent suggestions, GPT-5.2-Codex allows developers to focus on higher-level architecture and problem-solving.

However, we also recognize the risks associated with automated code generation, such as potential security vulnerabilities. To address this, we have integrated new safety filters and alignment techniques to reduce the likelihood of the model generating insecure code patterns.

### Evaluation and safety

We conducted extensive red-teaming with internal and external security experts to evaluate GPT-5.2-Codex. This testing focused on:

1.  **Cybersecurity:** Ensuring the model refuses to generate malware or exploit code.
2.  **Code Quality:** Verifying that generated code follows modern security best practices.
3.  **Bias:** checking that variable naming and comments do not reflect harmful stereotypes.

The results of these evaluations are detailed in our <a href="#">system card</a>.

## Empowering developers with new API features

Along with the model release, we are updating our API with features designed for developer productivity:

- **JSON Mode:** Guarantees valid JSON output for reliable parsing.
- **Function Calling:** Improved ability to connect to external tools and APIs.
- **Seed:** clearer reproducibility for testing and debugging.

We are excited to see what the community builds with GPT-5.2-Codex. Whether you are building an AI-powered IDE, a data analysis agent, or simply automating your own workflows, we hope this model serves as a powerful new tool in your kit.

## What's next

We are continuing to invest in model efficiency and reasoning capabilities. Future updates will focus on even deeper integration with developer environments and supporting more programming languages.

We invite developers to try GPT-5.2-Codex in the API Playground and share their feedback.
